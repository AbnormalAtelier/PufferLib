[base]
package = ocean
env_name = my_pong

[env]
num_envs = 1024

[train]
total_timesteps = 10_000_000_000
num_envs = 10
num_workers = 10
env_batch_size = 1
batch_size = 819200
update_epochs = 1
minibatch_size = 20480
bptt_horizon = 16
anneal_lr = False
gae_lambda = 0.98
gamma = 0.999
clip_coef = 0.01
vf_coef = 0.4
vf_clip_coef = 0.25
max_grad_norm = 0.8
ent_coef = 0.01
learning_rate = 0.0001
checkpoint_interval = 200
device = cpu

[sweep.metric]
goal = maximize
name = environment/reward
