[base]
package = ocean
env_name = trash_pickup puffer_trash_pickup 
policy_name = TrashPickup

[env]
num_envs = 2048  # 4096 (recommended start value) / num_agents (2) = 2048
grid_size = 6
num_agents = 2  # must be greater than 1 and preferably a power of 2
num_trash = 2
num_bins = 1
max_steps = 150
report_interval = 1

[train]
total_timesteps = 500_000_000
checkpoint_interval = 200
num_envs = 1
num_workers = 1
env_batch_size = 1
batch_size = 2097152
update_epochs = 3
minibatch_size = 524288
bptt_horizon = 128
anneal_lr = False
device = cuda
learning_rate=0.0003
gamma = 0.99
gae_lambda = 0.95
vf_ceof = 0.5
clip_coef = 0.1
cf_clip_coef = 0.1

[sweep.metric]
goal = maximize
name = environment/episode_return

[sweep.parameters.train.parameters.learning_rate]
distribution = uniform
min = 0.000001
max = 0.01

[sweep.parameters.train.parameters.clip_coef]
distribution = uniform
min = 0.01
max = 0.3

[sweep.parameters.train.parameters.vf_ceof]
distribution = uniform
min = 0.01
max = 0.5
