[base]
package = ocean
env_name = puffer_gpudrive
policy_name = GPUDrive
rnn_name = Recurrent

[vec]
num_workers = 8
num_envs = 8
batch_size = 2
#backend = Serial

[policy]
input_size = 64
hidden_size = 512

[rnn]
input_size = 512
hidden_size = 512

[env]
num_agents = 2048
reward_vehicle_collision = -0.6427606261643138
reward_offroad_collision = -0.37311187505970733
spawn_immunity_timer = 25
num_maps = 500
[train]
total_timesteps = 250_000_000
#learning_rate = 0.005
anneal_lr = True
batch_size = 1490944
minibatch_size = 23296
max_minibatch_size = 23296
bptt_horizon = 91

#adam_beta1 = 0.9225899639773112
#adam_beta2 = 0.9
#adam_eps = 0.0004030478187254784
#ent_coef = 0.0020159472963835016
#gae_lambda = 0.8829440612065992
#gamma = 0.9872971455373439
#learning_rate = 0.0003947934701844728
#max_grad_norm = 0.5296288081133984
#prio_alpha = 0.99
#prio_beta0 = 0.48469847315324566
#update_epochs = 2
#vf_coef = 3.6777541336880786
#checkpoint_interval = 1000

adam_beta1 = 0.8951942423819854
adam_beta2 = 0.9999876378221901
adam_eps = 0.0001
clip_coef = 0.2620285873605262
ent_coef = 0.002950372091183814
gae_lambda = 0.95
gamma = 0.98
learning_rate = 0.02
max_grad_norm = 0.643425131018516
prio_alpha = 0.8275071049453291
prio_beta = 0.9429842108374631
prio_beta0 = 0.5354839563808427
vf_clip_coef = 0.29471365941524824
vf_coef = 3.388064828792835

[sweep.train.total_timesteps]
distribution = log_normal
min = 1e8
max = 3e8
mean = 1.5e8
scale = time
 
[sweep.env.reward_vehicle_collision]
distribution = uniform
min = -1.0
max = 0.0
mean = -0.5
scale = auto 
 
[sweep.env.reward_offroad_collision]
distribution = uniform
min = -1.0
max = 0.0
mean = -0.5
scale = auto

[sweep.env.spawn_immunity_timer]
distribution = uniform
min = 1
max = 91
mean = 30
scale = auto
