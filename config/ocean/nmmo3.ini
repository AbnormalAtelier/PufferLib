[base]
package = ocean
env_name = puffer_nmmo3
vec = multiprocessing
policy_name = NMMO3
rnn_name = NMMO3LSTM

[env]
reward_combat_level = 2.9437930583953857
reward_prof_level = 1.445250153541565
reward_item_level = 1.3669428825378418
reward_market = 0
reward_death = -2.46451187133789
num_envs = 4

[train]
total_timesteps = 107000000000
checkpoint_interval = 1000
learning_rate = 0.0003
precond_lr = 0.1
minibatch_size = 32768

[sweep.metric]
goal = maximize
name = episode_return

[sweep.env.num_envs]
distribution = uniform_pow2
min = 1
max = 8
mean = 4
scale = 0.5

[sweep.train.total_timesteps]
distribution = log_normal
min = 2e8
max = 1e9
mean = 5e8
scale = 0.5

[sweep.env.reward_combat_level]
distribution = uniform
min = 0.0
max = 1.0
mean = 0.5
scale = auto

[sweep.env.reward_prof_level]
distribution = uniform
min = 0.0
max = 1.0
mean = 0.5
scale = auto

[sweep.env.reward_item_level]
distribution = uniform
min = 0.0
max = 1.0
mean = 1.0
scale = auto

[sweep.env.reward_death]
distribution = uniform
min = -1.0
max = 0.0
mean = -1.0
scale = auto
