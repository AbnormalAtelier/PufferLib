[base]
package = metta
env_name = metta 
policy_name = Policy
rnn_name = Recurrent

[vec]
num_envs = 16

[env]
render_mode = auto

[train]
total_timesteps = 150_000_000

batch_size = auto
minibatch_size = 32768

[sweep]
metric = agent/heart.gained

[sweep.train.total_timesteps]
distribution = log_normal
min = 1e8
max = 5e8
mean = 3e8
scale = auto

[sweep.env.ore_reward]
distribution = uniform
min = 0.0
mean = 0.25
max = 1.0
scale = auto

[sweep.env.battery_reward]
distribution = uniform
min = 0.0
mean = 0.5
max = 1.0
scale = auto

[sweep.env.heart_reward]
distribution = uniform
min = 0.0
mean = 1.0
max = 1.0
scale = auto
